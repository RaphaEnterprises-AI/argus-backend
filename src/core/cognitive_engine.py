"""
Cognitive Testing Engine - The Brain of the System

This is NOT just another test runner. This is an AI system that:
1. UNDERSTANDS applications semantically (not just DOM/pixels)
2. LEARNS user behavior patterns from production
3. PREDICTS failures before they manifest
4. GENERATES tests autonomously from understanding
5. EVOLVES tests as the application changes

This is what makes us FUNDAMENTALLY different from Applitools/Testim/Mabl.
They automate testing. We THINK about testing.
"""

import json
import asyncio
import structlog
from enum import Enum
from typing import Optional, AsyncIterator
from dataclasses import dataclass, field
from datetime import datetime, timezone
from anthropic import AsyncAnthropic

from src.config import get_settings
from src.core.model_registry import get_model_id
from src.services.cache import cache_llm_response

logger = structlog.get_logger()


class UnderstandingLevel(str, Enum):
    """How deeply we understand an application component."""
    STRUCTURAL = "structural"      # We know DOM structure
    BEHAVIORAL = "behavioral"      # We know how it responds to actions
    SEMANTIC = "semantic"          # We understand its PURPOSE
    PREDICTIVE = "predictive"      # We can predict its behavior


@dataclass
class ApplicationModel:
    """
    A cognitive model of the application under test.

    This is NOT a sitemap or DOM tree. This is a SEMANTIC understanding
    of what the application DOES and WHY.
    """
    app_id: str
    name: str

    # Semantic understanding
    purpose: str  # "E-commerce platform for selling electronics"
    user_personas: list[dict] = field(default_factory=list)
    core_user_journeys: list[dict] = field(default_factory=list)
    business_rules: list[dict] = field(default_factory=list)

    # Learned patterns
    common_flows: list[dict] = field(default_factory=list)
    error_patterns: list[dict] = field(default_factory=list)
    performance_baselines: dict = field(default_factory=dict)

    # Behavioral model
    state_machine: dict = field(default_factory=dict)  # App states and transitions
    invariants: list[str] = field(default_factory=list)  # Things that should ALWAYS be true

    # Prediction model
    risk_areas: list[dict] = field(default_factory=list)
    failure_predictions: list[dict] = field(default_factory=list)

    # Evolution tracking
    version: str = "1.0"
    last_learned: Optional[datetime] = None
    confidence_score: float = 0.0


@dataclass
class CognitiveInsight:
    """An insight generated by the cognitive engine."""
    type: str  # "anomaly", "prediction", "suggestion", "understanding"
    severity: str  # "critical", "high", "medium", "low", "info"
    title: str
    description: str
    evidence: list[str] = field(default_factory=list)
    recommended_action: Optional[str] = None
    confidence: float = 0.0
    generated_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))


class CognitiveTestingEngine:
    """
    The core AI engine that THINKS about testing.

    Key innovations:
    1. Builds semantic understanding of applications
    2. Learns from production behavior
    3. Generates tests from understanding (not templates)
    4. Predicts failures before they happen
    5. Evolves continuously without human intervention
    """

    def __init__(self, model: Optional[str] = None):
        self.settings = get_settings()
        api_key = self.settings.anthropic_api_key
        if hasattr(api_key, 'get_secret_value'):
            api_key = api_key.get_secret_value()
        self.client = AsyncAnthropic(api_key=api_key)
        self.model = model or get_model_id("claude-sonnet-4-5")
        self.app_models: dict[str, ApplicationModel] = {}
        self.log = logger.bind(component="cognitive_engine", model=self.model)

    async def learn_application(
        self,
        app_url: str,
        source_code_path: Optional[str] = None,
        production_logs: Optional[list[dict]] = None,
        user_sessions: Optional[list[dict]] = None,
        api_specs: Optional[dict] = None,
        design_docs: Optional[str] = None
    ) -> ApplicationModel:
        """
        Learn and build a cognitive model of an application.

        This is NOT crawling. This is UNDERSTANDING.
        We synthesize multiple sources to build semantic understanding.
        """
        app_id = self._generate_app_id(app_url)

        # Start with empty model
        model = ApplicationModel(
            app_id=app_id,
            name=app_url,
            purpose=""
        )

        # Phase 1: Structural Understanding
        # Crawl and map the application structure
        structural_data = await self._analyze_structure(app_url)

        # Phase 2: Behavioral Understanding
        # Interact with the app to understand how it behaves
        behavioral_data = await self._analyze_behavior(app_url, structural_data)

        # Phase 3: Semantic Understanding
        # Use Claude to synthesize a deep understanding
        semantic_understanding = await self._build_semantic_model(
            app_url=app_url,
            structural_data=structural_data,
            behavioral_data=behavioral_data,
            source_code=source_code_path,
            api_specs=api_specs,
            design_docs=design_docs
        )

        # Phase 4: Learn from Production (if available)
        if production_logs or user_sessions:
            production_insights = await self._learn_from_production(
                production_logs or [],
                user_sessions or []
            )
            semantic_understanding.update(production_insights)

        # Phase 5: Build Predictive Model
        predictions = await self._build_predictions(
            structural_data,
            behavioral_data,
            semantic_understanding
        )

        # Compile into ApplicationModel
        model.purpose = semantic_understanding.get("purpose", "")
        model.user_personas = semantic_understanding.get("personas", [])
        model.core_user_journeys = semantic_understanding.get("journeys", [])
        model.business_rules = semantic_understanding.get("rules", [])
        model.invariants = semantic_understanding.get("invariants", [])
        model.state_machine = behavioral_data.get("state_machine", {})
        model.risk_areas = predictions.get("risk_areas", [])
        model.last_learned = datetime.now(timezone.utc)
        model.confidence_score = semantic_understanding.get("confidence", 0.5)

        self.app_models[app_id] = model
        return model

    @cache_llm_response(key_prefix="semantic_model")
    async def _call_semantic_model_llm(self, context: str) -> dict:
        """Make cached LLM call for semantic model building."""
        response = await self.client.messages.create(
            model=self.model,
            max_tokens=4096,
            system="""You are a cognitive AI that UNDERSTANDS applications deeply.

Your task is to build a semantic model of this application. Not just what it looks like,
but what it DOES, WHY it exists, and HOW users interact with it.

Think like a senior QA engineer who has used this application for years and understands
every nuance of its behavior.

Output a JSON object with:
{
    "purpose": "What this application fundamentally does",
    "personas": [{"name": "...", "goals": [...], "pain_points": [...]}],
    "journeys": [{"name": "...", "steps": [...], "success_criteria": [...], "priority": "critical|high|medium|low"}],
    "rules": [{"rule": "...", "when_violated": "...", "severity": "..."}],
    "invariants": ["Things that should ALWAYS be true"],
    "edge_cases": ["Scenarios that might break"],
    "confidence": 0.0-1.0
}""",
            messages=[{
                "role": "user",
                "content": context
            }]
        )

        try:
            text = response.content[0].text
            json_start = text.find("{")
            json_end = text.rfind("}") + 1
            if json_start >= 0:
                return json.loads(text[json_start:json_end])
        except (json.JSONDecodeError, IndexError, AttributeError) as e:
            self.log.warning("Failed to parse semantic model response", error=str(e))

        return {"purpose": "Unknown", "confidence": 0.3}

    async def _build_semantic_model(
        self,
        app_url: str,
        structural_data: dict,
        behavioral_data: dict,
        source_code: Optional[str],
        api_specs: Optional[dict],
        design_docs: Optional[str]
    ) -> dict:
        """Use Claude to build deep semantic understanding (cached)."""

        context_parts = [
            f"Application URL: {app_url}",
            f"\nStructural Analysis:\n{json.dumps(structural_data, indent=2)[:5000]}",
            f"\nBehavioral Analysis:\n{json.dumps(behavioral_data, indent=2)[:5000]}",
        ]

        if api_specs:
            context_parts.append(f"\nAPI Specification:\n{json.dumps(api_specs, indent=2)[:3000]}")

        if design_docs:
            context_parts.append(f"\nDesign Documentation:\n{design_docs[:3000]}")

        context = "\n".join(context_parts)
        return await self._call_semantic_model_llm(context)

    async def _analyze_structure(self, app_url: str) -> dict:
        """Analyze application structure using Cloudflare Browser Rendering."""
        # This would use Cloudflare's browser rendering API
        # For now, return placeholder
        return {
            "pages": [],
            "components": [],
            "navigation": [],
            "forms": [],
            "api_endpoints": []
        }

    async def _analyze_behavior(self, app_url: str, structure: dict) -> dict:
        """Analyze how the application behaves."""
        return {
            "state_machine": {},
            "transitions": [],
            "error_states": []
        }

    async def _learn_from_production(
        self,
        logs: list[dict],
        sessions: list[dict]
    ) -> dict:
        """Learn patterns from production data."""
        return {
            "common_paths": [],
            "error_patterns": [],
            "timing_baselines": {}
        }

    async def _build_predictions(
        self,
        structural: dict,
        behavioral: dict,
        semantic: dict
    ) -> dict:
        """Build predictive model of likely failures."""
        return {
            "risk_areas": [],
            "likely_regressions": []
        }

    def _generate_app_id(self, url: str) -> str:
        """Generate unique app ID."""
        import hashlib
        return hashlib.md5(url.encode()).hexdigest()[:12]

    async def generate_autonomous_tests(
        self,
        app_model: ApplicationModel,
        focus_areas: Optional[list[str]] = None
    ) -> AsyncIterator[dict]:
        """
        Generate tests AUTONOMOUSLY from application understanding.

        This is NOT template-based generation. We CREATE tests based on
        our semantic understanding of what the application SHOULD do.
        """

        prompt = f"""Based on this application understanding, generate comprehensive test scenarios.

APPLICATION MODEL:
- Purpose: {app_model.purpose}
- User Journeys: {json.dumps(app_model.core_user_journeys[:5], indent=2)}
- Business Rules: {json.dumps(app_model.business_rules[:10], indent=2)}
- Invariants: {app_model.invariants[:10]}
- Risk Areas: {json.dumps(app_model.risk_areas[:5], indent=2)}

Generate tests that:
1. Verify core user journeys work correctly
2. Ensure business rules are enforced
3. Check invariants are never violated
4. Probe risk areas for potential failures
5. Test edge cases that real users might hit

For each test, provide:
{{
    "name": "Test name",
    "category": "journey|rule|invariant|risk|edge_case",
    "priority": "critical|high|medium|low",
    "description": "What this tests",
    "preconditions": ["State requirements"],
    "steps": [
        {{"action": "...", "target": "...", "value": "..."}}
    ],
    "assertions": [
        {{"type": "...", "target": "...", "expected": "..."}}
    ],
    "rationale": "Why this test matters"
}}

Output as JSON array."""

        response = await self.client.messages.create(
            model=self.model,
            max_tokens=8192,
            messages=[{"role": "user", "content": prompt}]
        )

        try:
            text = response.content[0].text
            json_start = text.find("[")
            json_end = text.rfind("]") + 1
            if json_start >= 0:
                tests = json.loads(text[json_start:json_end])
                for test in tests:
                    yield test
        except (json.JSONDecodeError, IndexError, AttributeError) as e:
            self.log.warning("Failed to parse generated tests", error=str(e))

    @cache_llm_response(key_prefix="predict_failures")
    async def _call_predict_failures_llm(self, prompt: str) -> list[dict]:
        """Make cached LLM call for failure prediction."""
        response = await self.client.messages.create(
            model=self.model,
            max_tokens=4096,
            messages=[{"role": "user", "content": prompt}]
        )

        try:
            text = response.content[0].text
            json_start = text.find("[")
            json_end = text.rfind("]") + 1
            if json_start >= 0:
                return json.loads(text[json_start:json_end])
        except (json.JSONDecodeError, IndexError, AttributeError) as e:
            self.log.warning("Failed to parse failure predictions", error=str(e))

        return []

    async def predict_failures(
        self,
        app_model: ApplicationModel,
        code_changes: Optional[dict] = None,
        recent_errors: Optional[list[dict]] = None
    ) -> list[CognitiveInsight]:
        """
        PREDICT failures before they happen (cached).

        This is PROACTIVE, not reactive. We analyze:
        - Code changes and their potential impact
        - Error pattern trends
        - Application complexity hotspots
        - Historical failure correlations
        """
        prompt = f"""Analyze this application for potential failures.

APPLICATION:
- Purpose: {app_model.purpose}
- Risk Areas: {json.dumps(app_model.risk_areas, indent=2)}
- Known Error Patterns: {json.dumps(app_model.error_patterns[:10], indent=2)}

{"CODE CHANGES:" + json.dumps(code_changes, indent=2) if code_changes else ""}
{"RECENT ERRORS:" + json.dumps(recent_errors[:20], indent=2) if recent_errors else ""}

Predict potential failures:
1. What might break based on complexity and change patterns?
2. What error patterns are trending upward?
3. What untested paths might have bugs?
4. What timing/race conditions might occur?

For each prediction:
{{
    "type": "prediction",
    "severity": "critical|high|medium|low",
    "title": "Short title",
    "description": "Detailed explanation",
    "evidence": ["Why you think this"],
    "recommended_action": "What to do",
    "confidence": 0.0-1.0,
    "affected_area": "Where in the app"
}}

Output as JSON array."""

        predictions = await self._call_predict_failures_llm(prompt)

        insights = []
        for pred in predictions:
            insights.append(CognitiveInsight(
                type=pred.get("type", "prediction"),
                severity=pred.get("severity", "medium"),
                title=pred.get("title", ""),
                description=pred.get("description", ""),
                evidence=pred.get("evidence", []),
                recommended_action=pred.get("recommended_action"),
                confidence=pred.get("confidence", 0.5)
            ))

        return insights

    @cache_llm_response(key_prefix="explain_failure")
    async def _call_explain_failure_llm(self, prompt: str) -> str:
        """Make cached LLM call for failure explanation."""
        response = await self.client.messages.create(
            model=self.model,
            max_tokens=2048,
            messages=[{"role": "user", "content": prompt}]
        )

        try:
            return response.content[0].text
        except (IndexError, AttributeError) as e:
            self.log.warning("Failed to extract failure explanation", error=str(e))
            return "Unable to generate failure explanation"

    async def explain_failure(
        self,
        app_model: ApplicationModel,
        failure_context: dict
    ) -> CognitiveInsight:
        """
        Explain a failure in HUMAN terms (cached).

        Not just "element not found" but WHY it happened,
        what the user was trying to do, and how to fix it.
        """

        prompt = f"""A test failed. Explain it like a senior QA engineer would.

APPLICATION CONTEXT:
- Purpose: {app_model.purpose}
- This journey: {json.dumps(failure_context.get('journey', {}), indent=2)}

FAILURE DETAILS:
{json.dumps(failure_context, indent=2)}

Explain:
1. What was the user trying to accomplish?
2. What went wrong in BUSINESS terms (not technical)?
3. Is this a real bug or a test issue?
4. What's the root cause?
5. How should it be fixed?
6. What's the user impact?

Be specific and actionable."""

        description = await self._call_explain_failure_llm(prompt)

        return CognitiveInsight(
            type="explanation",
            severity=failure_context.get("severity", "medium"),
            title=f"Failure in {failure_context.get('test_name', 'Unknown Test')}",
            description=description,
            evidence=[],
            confidence=0.8
        )

    @cache_llm_response(key_prefix="test_improvements")
    async def _call_suggest_improvements_llm(self, prompt: str) -> list[dict]:
        """Make cached LLM call for test improvement suggestions."""
        response = await self.client.messages.create(
            model=self.model,
            max_tokens=4096,
            messages=[{"role": "user", "content": prompt}]
        )

        try:
            text = response.content[0].text
            json_start = text.find("[")
            json_end = text.rfind("]") + 1
            if json_start >= 0:
                return json.loads(text[json_start:json_end])
        except (json.JSONDecodeError, IndexError, AttributeError) as e:
            self.log.warning("Failed to parse test improvement suggestions", error=str(e))

        return []

    async def suggest_test_improvements(
        self,
        app_model: ApplicationModel,
        current_tests: list[dict],
        coverage_data: Optional[dict] = None
    ) -> list[CognitiveInsight]:
        """
        Suggest how to improve test coverage and quality (cached).

        Analyzes gaps between what we understand about the app
        and what the current tests cover.
        """
        # Analyze coverage gaps
        prompt = f"""Analyze test coverage and suggest improvements.

APPLICATION UNDERSTANDING:
- User Journeys: {json.dumps(app_model.core_user_journeys, indent=2)}
- Business Rules: {json.dumps(app_model.business_rules, indent=2)}
- Risk Areas: {json.dumps(app_model.risk_areas, indent=2)}

CURRENT TESTS:
{json.dumps([{"name": t.get("name"), "category": t.get("category")} for t in current_tests[:50]], indent=2)}

{"COVERAGE DATA:" + json.dumps(coverage_data, indent=2) if coverage_data else ""}

Identify:
1. Critical journeys without test coverage
2. Business rules not being validated
3. Risk areas not being tested
4. Redundant or low-value tests
5. Missing edge cases

For each suggestion:
{{
    "type": "suggestion",
    "severity": "critical|high|medium|low",
    "title": "Short title",
    "description": "What's missing and why it matters",
    "recommended_action": "Specific test to add or change",
    "confidence": 0.0-1.0
}}"""

        suggestions = await self._call_suggest_improvements_llm(prompt)

        insights = []
        for sug in suggestions:
            insights.append(CognitiveInsight(
                type="suggestion",
                severity=sug.get("severity", "medium"),
                title=sug.get("title", ""),
                description=sug.get("description", ""),
                recommended_action=sug.get("recommended_action"),
                confidence=sug.get("confidence", 0.5)
            ))

        return insights
