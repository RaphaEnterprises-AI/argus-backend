# E2E Testing Agent Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# REQUIRED
# =============================================================================

# Anthropic API Key (get from https://console.anthropic.com)
ANTHROPIC_API_KEY=sk-ant-...

# =============================================================================
# OPTIONAL - Integrations
# =============================================================================

# GitHub token for PR integration
GITHUB_TOKEN=ghp_...

# Database connection (for DB testing)
DATABASE_URL=postgresql://user:pass@localhost:5432/dbname

# Slack webhook for notifications
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/...

# =============================================================================
# MULTI-MODEL CONFIGURATION (Cost Optimization)
# =============================================================================

# Model routing strategy:
# - anthropic_only: Use only Claude models (simplest, most expensive)
# - cost_optimized: Use cheapest model for each task (60-80% savings)
# - balanced: Balance cost and quality (recommended)
# - quality_first: Use best model, fallback to cheaper
MODEL_STRATEGY=balanced

# Inference Gateway (how to access AI models):
# - cloudflare: Cloudflare AI Gateway (recommended - unified billing, edge caching)
# - direct: Direct API calls to each provider
# - aws_bedrock: AWS Bedrock (enterprise)
# - azure: Azure OpenAI
INFERENCE_GATEWAY=cloudflare

# Cloudflare AI Gateway (if using cloudflare gateway)
CLOUDFLARE_ACCOUNT_ID=your_account_id
CLOUDFLARE_GATEWAY_ID=your_gateway_id

# =============================================================================
# API KEYS - Multi-Provider (for cost optimization)
# =============================================================================

# OpenAI API Key (for GPT-4o, GPT-4o-mini)
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-...

# Google AI API Key (for Gemini, Gemini Computer Use)
# Get from: https://aistudio.google.com/apikey
GOOGLE_API_KEY=AIza...

# Groq API Key (for ultra-fast Llama inference - 100ms latency!)
# Get from: https://console.groq.com/keys
GROQ_API_KEY=gsk_...

# Together API Key (for DeepSeek, open models)
# Get from: https://api.together.xyz/settings/api-keys
TOGETHER_API_KEY=...

# =============================================================================
# VERTEX AI CONFIGURATION (Claude via Google Cloud)
# =============================================================================
# Benefits:
# - Unified GCP billing (use committed spend discounts)
# - Enterprise features (VPC-SC, IAM, audit logging)
# - Regional data residency (EU/US compliance)
# - Full Computer Use support
# - Same pricing as direct Anthropic API

# Enable Vertex AI for Claude models (set to true to use Vertex AI)
USE_VERTEX_AI=false

# GCP Project ID (required if USE_VERTEX_AI=true)
# Find in: https://console.cloud.google.com/
GOOGLE_CLOUD_PROJECT=your-gcp-project-id

# Vertex AI Region:
# - "global": Dynamic routing for max availability (recommended, no premium)
# - "us-east1", "europe-west1", etc.: Regional endpoints (10% premium, data residency)
VERTEX_AI_REGION=global

# Setup steps:
# 1. pip install anthropic[vertex]
# 2. gcloud auth application-default login
# 3. Enable Vertex AI API in GCP Console
# 4. Set GOOGLE_CLOUD_PROJECT above

# =============================================================================
# LEGACY MODEL CONFIGURATION (for anthropic_only mode)
# =============================================================================

# Default model for testing (claude-sonnet-4-5 recommended)
DEFAULT_MODEL=claude-sonnet-4-5

# Fast model for quick verifications
VERIFICATION_MODEL=claude-haiku-4-5

# Powerful model for complex debugging
DEBUGGING_MODEL=claude-opus-4-5

# =============================================================================
# ARGUS ARCHITECTURE (Brain + Browser Worker)
# =============================================================================
# Argus has two main components:
# 1. Brain (Python/LangGraph) - Orchestration, code analysis, planning
# 2. Browser Worker (Cloudflare) - Browser automation, self-healing
#
# For local development:
# - Brain: python -m uvicorn src.api.server:app --port 8000
# - Worker: Already deployed at argus-api.samuelvinay-kumar.workers.dev
#
# For production, deploy Brain to Railway/Render/Fly.io

# =============================================================================
# BROWSER AUTOMATION WORKER (Cloudflare - Required)
# =============================================================================

# URL of the Argus Browser Automation Worker
# Default public worker: https://argus-api.samuelvinay-kumar.workers.dev
# To deploy your own: cd cloudflare-worker && npm run deploy
BROWSER_WORKER_URL=https://argus-api.samuelvinay-kumar.workers.dev

# =============================================================================
# DASHBOARD CONFIGURATION
# =============================================================================

# Argus Brain URL (Python backend for full orchestration)
# Set this when deploying the Python backend to Railway/Render/Fly.io
# Local: http://localhost:8000
# Production: https://your-argus-brain.railway.app
ARGUS_BACKEND_URL=http://localhost:8000

# Cloudflare Worker URL for dashboard (browser automation)
E2E_WORKER_URL=https://argus-api.samuelvinay-kumar.workers.dev

# =============================================================================
# LEGACY: STAGEHAND CONFIGURATION (kept for backwards compatibility)
# =============================================================================

# Enable Stagehand for browser automation (now via Cloudflare Worker)
USE_STAGEHAND=true

# Stagehand model provider: "workers-ai" (free), "openai", "anthropic"
STAGEHAND_MODEL_PROVIDER=openai

# Enable selector caching (faster repeated actions)
STAGEHAND_CACHE_ENABLED=true

# Enable self-healing (auto-fix broken selectors)
STAGEHAND_SELF_HEALING=true

# =============================================================================
# LEGACY COMPUTER USE SETTINGS (if not using Stagehand)
# =============================================================================

# Screenshot resolution
SCREENSHOT_WIDTH=1920
SCREENSHOT_HEIGHT=1080

# Maximum iterations per test
MAX_ITERATIONS=50

# Action timeout in milliseconds
ACTION_TIMEOUT_MS=10000

# =============================================================================
# COST CONTROLS
# =============================================================================

# Maximum cost per test run in USD
COST_LIMIT_PER_RUN=10.00

# Maximum cost per individual test in USD
COST_LIMIT_PER_TEST=1.00

# =============================================================================
# EXECUTION SETTINGS
# =============================================================================

# Number of tests to run in parallel
PARALLEL_TESTS=1

# Number of retries for failed tests
RETRY_FAILED_TESTS=2

# Enable automatic test healing
SELF_HEAL_ENABLED=true

# Minimum confidence for auto-healing (0.0 to 1.0)
SELF_HEAL_CONFIDENCE_THRESHOLD=0.8

# =============================================================================
# OUTPUT SETTINGS
# =============================================================================

# Directory for test outputs
OUTPUT_DIR=./test-results

# Directory for screenshots
SCREENSHOT_DIR=./test-results/screenshots

# =============================================================================
# SERVER SETTINGS (for webhook mode)
# =============================================================================

# Server host
SERVER_HOST=0.0.0.0

# Server port
SERVER_PORT=8000

# =============================================================================
# LangGraph Configuration
# =============================================================================

# Database URL for PostgresSaver (required for durable execution)
# DATABASE_URL is already defined above - it's used for both DB testing and LangGraph persistence

# Enable human-in-the-loop approvals
ENABLE_HUMAN_APPROVAL=false

# Nodes requiring approval before execution
APPROVAL_REQUIRED_NODES=execute_test,self_heal

# Timeout for approval requests (seconds)
APPROVAL_TIMEOUT=300

# =============================================================================
# Memory Store Configuration
# =============================================================================

# OpenAI API key for embeddings (required for semantic search)
# OPENAI_API_KEY is already defined above

# Embedding model for semantic search
EMBEDDING_MODEL=text-embedding-3-small

# Minimum similarity score for memory retrieval
MEMORY_SIMILARITY_THRESHOLD=0.7

# =============================================================================
# Supabase Configuration (for LangGraph persistence)
# =============================================================================

# Supabase project URL
SUPABASE_URL=https://your-project.supabase.co

# Supabase service role key (for server-side operations)
SUPABASE_SERVICE_KEY=eyJhbGci...

# Supabase anon key (for client-side operations)
SUPABASE_ANON_KEY=eyJhbGci...

# =============================================================================
# SECURITY SETTINGS (SOC2 Compliance)
# =============================================================================

# Enable authentication enforcement (set to true in production)
ENFORCE_AUTHENTICATION=false

# JWT Secret Key (required for internal JWT auth - generate with: openssl rand -hex 32)
JWT_SECRET_KEY=your-secret-key-here-generate-with-openssl-rand-hex-32

# =============================================================================
# CLERK INTEGRATION (Dashboard SSO)
# =============================================================================
# Configure these to enable Clerk JWT verification from the dashboard
# Get your JWKS URL from: https://dashboard.clerk.com → API Keys → Advanced

# Clerk JWKS URL for JWT verification
# Format: https://<your-clerk-frontend-api>.clerk.accounts.dev/.well-known/jwks.json
CLERK_JWKS_URL=https://your-clerk-instance.clerk.accounts.dev/.well-known/jwks.json

# Clerk Issuer (optional, for extra security)
# Format: https://<your-clerk-frontend-api>.clerk.accounts.dev
CLERK_ISSUER=

# JWT token expiration in hours
JWT_EXPIRATION_HOURS=24

# JWT refresh token expiration in days
JWT_REFRESH_EXPIRATION_DAYS=30

# Enable rate limiting
RATE_LIMITING_ENABLED=true

# Rate limit: requests per window
RATE_LIMIT_REQUESTS=60

# Rate limit window in seconds
RATE_LIMIT_WINDOW_SECONDS=60

# CORS allowed origins (comma-separated, use specific domains in production)
CORS_ALLOWED_ORIGINS=*

# Enable HSTS header
ENABLE_HSTS=true

# HSTS max-age in seconds (1 year recommended)
HSTS_MAX_AGE=31536000

# Enable Content-Security-Policy header
ENABLE_CSP=true

# Enable comprehensive audit logging
AUDIT_LOGGING_ENABLED=true

# Log request bodies (enable with caution - may contain sensitive data)
AUDIT_LOG_REQUEST_BODY=false

# Log response bodies (enable with caution - may contain sensitive data)
AUDIT_LOG_RESPONSE_BODY=false

# Audit log retention in days (SOC2 requires minimum 365)
AUDIT_LOG_RETENTION_DAYS=365

# Max request body size in bytes (10MB default)
MAX_REQUEST_BODY_SIZE=10485760

# Max string field length
MAX_STRING_LENGTH=10000

# Max array length in requests
MAX_ARRAY_LENGTH=1000

# Session timeout in minutes
SESSION_TIMEOUT_MINUTES=60

# Max concurrent sessions per user
MAX_CONCURRENT_SESSIONS=5

# API version
API_VERSION=v1

# Enable deprecation warnings
DEPRECATION_WARNING_ENABLED=true
