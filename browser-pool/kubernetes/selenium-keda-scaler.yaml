---
# KEDA External Scaler for Selenium Grid
# This service queries Selenium Grid API and returns metrics for KEDA
# Deploys as a gRPC service that KEDA calls to get scaling metrics
apiVersion: v1
kind: ConfigMap
metadata:
  name: selenium-keda-scaler-code
  namespace: selenium-grid
data:
  scaler.py: |
    """
    KEDA External Scaler for Selenium Grid

    Queries Selenium Grid /status endpoint and returns:
    - session_queue_length: Number of sessions queued
    - sessions_active: Number of active sessions
    - nodes_available: Number of available nodes
    - slots_available: Number of available browser slots
    """

    import json
    import logging
    import os
    from concurrent import futures

    import grpc
    import requests

    # Import KEDA gRPC definitions
    # These are defined in the proto files (see generated files below)
    import externalscaler_pb2 as externalscaler
    import externalscaler_pb2_grpc as externalscaler_grpc

    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)

    class SeleniumGridScaler(externalscaler_grpc.ExternalScalerServicer):
        """KEDA External Scaler for Selenium Grid"""

        def __init__(self):
            self.hub_url = os.getenv('SELENIUM_HUB_URL', 'http://selenium-hub:4444')
            self.timeout = int(os.getenv('REQUEST_TIMEOUT', '5'))
            self.session = requests.Session()

        def IsActive(self, request, context):
            """Check if the metric should be active (above threshold)"""
            try:
                metric_value = self._get_metric(request.scalerMetadata)
                threshold = float(request.scalerMetadata.get('threshold', '1'))

                is_active = metric_value > 0
                logger.info(f"IsActive: metric={metric_value}, threshold={threshold}, active={is_active}")

                return externalscaler.IsActiveResponse(result=is_active)
            except Exception as e:
                logger.error(f"IsActive error: {e}")
                context.set_details(f"IsActive error: {e}")
                context.set_code(grpc.StatusCode.INTERNAL)
                return externalscaler.IsActiveResponse(result=False)

        def GetMetrics(self, request, context):
            """Get the current metric value"""
            try:
                metric_value = self._get_metric(request.scalerMetadata)

                metric_spec = externalscaler.MetricSpec(
                    metricName=request.scalerMetadata['metric'],
                    targetSize=int(metric_value)
                )

                logger.info(f"GetMetrics: {metric_spec.metricName}={metric_spec.targetSize}")

                return externalscaler.GetMetricsResponse(metrics=[metric_spec])
            except Exception as e:
                logger.error(f"GetMetrics error: {e}")
                context.set_details(f"GetMetrics error: {e}")
                context.set_code(grpc.StatusCode.INTERNAL)
                return externalscaler.GetMetricsResponse(metrics=[])

        def GetMetricSpec(self, request, context):
            """Return metric spec"""
            try:
                metric_name = request.scalerMetadata['metric']
                target_size = int(request.scalerMetadata.get('threshold', '10'))

                metric_spec = externalscaler.MetricSpec(
                    metricName=metric_name,
                    targetSize=target_size
                )

                return externalscaler.GetMetricSpecResponse(metricSpecs=[metric_spec])
            except Exception as e:
                logger.error(f"GetMetricSpec error: {e}")
                context.set_details(f"GetMetricSpec error: {e}")
                context.set_code(grpc.StatusCode.INTERNAL)
                return externalscaler.GetMetricSpecResponse(metricSpecs=[])

        def _get_metric(self, scaler_metadata):
            """Query Selenium Grid and return metric value"""
            metric_name = scaler_metadata.get('metric', 'session_queue_length')

            try:
                # Get Selenium Grid status
                response = self.session.get(
                    f'{self.hub_url}/status',
                    timeout=self.timeout
                )
                response.raise_for_status()

                status = response.json()
                logger.debug(f"Grid status: {json.dumps(status, indent=2)}")

                # Extract metric based on name
                value = self._extract_metric(status, metric_name)
                logger.info(f"Metric {metric_name}={value}")

                return float(value)

            except requests.exceptions.RequestException as e:
                logger.error(f"Failed to query Selenium Hub: {e}")
                # Return 0 on error (don't scale if we can't query)
                return 0
            except Exception as e:
                logger.error(f"Error extracting metric: {e}")
                return 0

        def _extract_metric(self, status, metric_name):
            """Extract metric from Selenium Grid status response"""

            if metric_name == 'session_queue_length':
                # Total queued sessions across all browsers
                return status.get('value', {}).get('ready', 0)

            elif metric_name == 'firefox_queue_length':
                # Firefox-specific queue
                # Navigate through the nested status structure
                queue = status.get('value', {}).get('sessionQueue', [])
                firefox_count = sum(
                    1 for session in queue
                    if session.get('capabilities', {}).get('browserName') == 'firefox'
                )
                return firefox_count

            elif metric_name == 'sessions_active':
                # Total active sessions
                return status.get('value', {}).get('nodeCount', 0)

            elif metric_name == 'slots_available':
                # Available browser slots
                max_sessions = status.get('value', {}).get('maxSession', 0)
                current_sessions = status.get('value', {}).get('sessionCount', 0)
                return max_sessions - current_sessions

            elif metric_name == 'nodes_available':
                # Number of available nodes
                return status.get('value', {}).get('nodeCount', 0)

            else:
                # Default: return queue length
                return status.get('value', {}).get('ready', 0)


    def serve():
        """Start the gRPC server"""
        server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
        externalscaler_grpc.add_ExternalScalerServicer_to_server(
            SeleniumGridScaler(), server
        )

        port = os.getenv('SCALER_PORT', '6000')
        server.add_insecure_port(f'[::]:{port}')

        logger.info(f"Starting KEDA External Scaler on port {port}...")
        server.start()
        server.wait_for_termination()


    if __name__ == '__main__':
        serve()

  externalscaler_pb2.py: |
    # Auto-generated Protocol Buffer file
    # This would normally be generated from externalscaler.proto
    # For production, use: python -m grpc_tools.protoc -I. --python_out=. --grpc_python_out=. externalscaler.proto

    # Placeholder - in production use actual generated file
    # See: https://github.com/kedacore/keda/blob/main/proto/externalscaler.proto

  externalscaler_pb2_grpc.py: |
    # Auto-generated gRPC file
    # Placeholder - in production use actual generated file
    # See: https://github.com/kedacore/keda/blob/main/proto/externalscaler.proto

  requirements.txt: |
    requests==2.31.0
    grpcio==1.59.0
    protobuf==4.24.0

---
# Deployment of the KEDA External Scaler
apiVersion: apps/v1
kind: Deployment
metadata:
  name: selenium-keda-scaler
  namespace: selenium-grid
  labels:
    app: selenium-keda-scaler
spec:
  replicas: 1
  selector:
    matchLabels:
      app: selenium-keda-scaler
  template:
    metadata:
      labels:
        app: selenium-keda-scaler
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8000"
        prometheus.io/path: "/metrics"
    spec:
      containers:
      - name: scaler
        image: python:3.11-slim
        imagePullPolicy: IfNotPresent

        workingDir: /app
        command: ["python", "scaler.py"]

        ports:
        - name: grpc
          containerPort: 6000
          protocol: TCP
        - name: metrics
          containerPort: 8000
          protocol: TCP

        env:
        - name: SELENIUM_HUB_URL
          value: "http://selenium-hub:4444"
        - name: REQUEST_TIMEOUT
          value: "5"
        - name: SCALER_PORT
          value: "6000"
        - name: LOG_LEVEL
          value: "INFO"

        resources:
          requests:
            cpu: 100m
            memory: 128Mi
          limits:
            cpu: 500m
            memory: 256Mi

        volumeMounts:
        - name: scaler-code
          mountPath: /app

        livenessProbe:
          tcpSocket:
            port: grpc
          initialDelaySeconds: 10
          periodSeconds: 30

        readinessProbe:
          tcpSocket:
            port: grpc
          initialDelaySeconds: 5
          periodSeconds: 10

      volumes:
      - name: scaler-code
        configMap:
          name: selenium-keda-scaler-code
          defaultMode: 0755

---
# Service exposing the KEDA External Scaler
apiVersion: v1
kind: Service
metadata:
  name: selenium-keda-scaler
  namespace: selenium-grid
  labels:
    app: selenium-keda-scaler
spec:
  type: ClusterIP
  ports:
  - name: grpc
    port: 6000
    targetPort: grpc
    protocol: TCP
  - name: metrics
    port: 8000
    targetPort: metrics
    protocol: TCP
  selector:
    app: selenium-keda-scaler

---
# Pod Disruption Budget to keep scaler always available
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: selenium-keda-scaler-pdb
  namespace: selenium-grid
spec:
  minAvailable: 1
  selector:
    matchLabels:
      app: selenium-keda-scaler
